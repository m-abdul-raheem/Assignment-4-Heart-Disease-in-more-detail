{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4, Heart Disease in more detail\n",
    "### deadline July 03, 11:59 PM\n",
    "\n",
    "In the last assingment, you did a basic analysis of the heart disease. Lets do a more detailed analysis of it. We have another heart disease dataset with 76 featuers. Usually, more features mean more information. Probably, we will be able to achieve better classification accuracy. Do all features give better  prediction? Or, can we ignore some of the features to achieve better accuracy. How many features give us the best classification accuracy? Which model works best with the optimized set of features? Which hypermeters are best for each model we choose? These are some of the questions that intrigue us. You have to explore these questions and come up with reasonable answers. You will submit your notebook with all the working. Your grading will be done on the level of detail and best answers you achieve.\n",
    "\n",
    "The data is present at [UCI machine learning data set](http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/cleveland.data). Some detail about the data is present at [link](http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/heart-disease.names).\n",
    "\n",
    "I will recommend to read Chapter 4 of 'Introduction to machine learning using Python' book by Andreas C Mueller. It notebook can be found at [link](https://github.com/amueller/introduction_to_ml_with_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22621\n",
      "         0       1       2       3      4             5     6      7       8   \\\n",
      "0       1.0     0.0    63.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     1.0   \n",
      "1       2.0     0.0    67.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "2       3.0     0.0    67.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "3       4.0     0.0    37.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "4       6.0     0.0    41.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     2.0   \n",
      "5       7.0     0.0    56.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     2.0   \n",
      "6       8.0     0.0    62.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "7       9.0     0.0    57.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "8      10.0     0.0    63.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "9      11.0     0.0    53.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "10     12.0     0.0    57.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "11     13.0     0.0    56.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     2.0   \n",
      "12     14.0     0.0    56.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "13     15.0     0.0    44.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     2.0   \n",
      "14     16.0     0.0    52.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "15     17.0     0.0    57.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "16     18.0     0.0    48.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     2.0   \n",
      "17     19.0     0.0    54.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "18     20.0     0.0    48.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "19     21.0     0.0    49.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     2.0   \n",
      "20     22.0     0.0    64.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     1.0   \n",
      "21     23.0     0.0    58.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     1.0   \n",
      "22     24.0     0.0    58.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     2.0   \n",
      "23     25.0     0.0    58.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "24     26.0     0.0    60.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "25     27.0     0.0    50.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "26     28.0     0.0    58.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "27     29.0     0.0    66.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     1.0   \n",
      "28     30.0     0.0    43.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "29     31.0     0.0    40.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "..      ...     ...     ...     ...    ...           ...   ...    ...     ...   \n",
      "267   284.0     0.0    59.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "268   285.0     0.0    40.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "269   286.0     0.0    42.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "270   287.0     0.0    61.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "271   288.0     0.0    66.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "272   289.0     0.0    46.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "273   290.0     0.0    71.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "274   291.0     0.0    59.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     1.0   \n",
      "275   292.0     0.0    64.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     1.0   \n",
      "276   293.0     0.0    66.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "277   294.0     0.0    39.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "278   295.0     0.0    57.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     2.0   \n",
      "279   296.0     0.0    58.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "280   297.0     0.0    57.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "281   298.0     0.0    47.0     1.0   -9.0 -9.000000e+00  -9.0   -9.0     3.0   \n",
      "282   299.0     0.0    55.0     0.0   -9.0 -9.000000e+00  -9.0   -9.0     4.0   \n",
      "283     4.0   128.0    -9.0    -9.0   -9.0 -9.000000e+00   4.0  128.0     0.0   \n",
      "284    12.0     0.0    -9.0   -69.0  169.0  0.000000e+00  -9.0   -9.0    -9.0   \n",
      "285     0.0     1.0    50.0     0.0    0.0  0.000000e+00   0.0    1.0    50.0   \n",
      "286     0.0     0.0     0.0     8.0   -9.0  0.000000e+00   0.0    8.0    35.0   \n",
      "287     0.0     0.0     0.0    -9.0    1.0 -2.000000e+00  -9.0    1.0   -21.0   \n",
      "288     0.0     1.0     9.0     1.0   92.0 -9.000000e+00   1.0    2.0     1.0   \n",
      "289     1.0     0.0     1.0     0.0    0.0  1.000000e+00   1.0    1.0     1.0   \n",
      "290   891.0     0.0     0.0  1940.0    0.0  1.940000e+02   2.0   -9.0    22.0   \n",
      "291    -9.0    -9.0    -9.0    -9.0   -7.0  2.449495e+09   1.0   12.0  1282.0   \n",
      "292  8426.0  8422.0     1.0    -9.0   -9.0 -9.000000e+00  -9.0   -9.0    -9.0   \n",
      "293  4659.0     1.0    -9.0  2081.0  681.0  6.880000e+03  71.0    1.0     1.0   \n",
      "294     0.0   237.0  1116.0    83.0   16.0  8.300000e+01   0.0    1.0     6.0   \n",
      "295  1100.0     0.0  4650.0    12.0   80.0  0.000000e+00   0.0   70.0     0.0   \n",
      "296     1.0     1.0     1.0     1.0    1.0 -9.000000e+00 -90.0    0.0     0.0   \n",
      "\n",
      "        9   ...      66      67      68     69     70       71      72     73  \\\n",
      "0    145.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "1    160.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "2    120.0  ...     2.0     2.0     1.0    1.0    1.0      7.0     3.0   -9.0   \n",
      "3    130.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "4    130.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "5    120.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "6    140.0  ...     2.0     1.0     1.0    1.0    1.0      7.0     1.0   -9.0   \n",
      "7    120.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "8    130.0  ...     2.0     1.0     1.0    1.0    6.0      7.0     2.0   -9.0   \n",
      "9    140.0  ...     2.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "10   140.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "11   140.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "12   130.0  ...     2.0     1.0     1.0    1.0    1.0      3.0     1.0   -9.0   \n",
      "13   120.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "14   172.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "15   150.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "16   110.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "17   140.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "18   130.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "19   130.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "20   110.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "21   150.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "22   120.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "23   132.0  ...     2.0     1.0     1.0    1.0    1.0      8.0     3.0   -9.0   \n",
      "24   130.0  ...     2.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "25   120.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "26   120.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "27   150.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "28   150.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "29   110.0  ...     2.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "..     ...  ...     ...     ...     ...    ...    ...      ...     ...    ...   \n",
      "267  126.0  ...     2.0     1.0     1.0    1.0    1.0      5.0     1.0   -9.0   \n",
      "268  152.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "269  130.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "270  140.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "271  160.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "272  140.0  ...     2.0     1.0     1.0    1.0    1.0      7.0     1.0   -9.0   \n",
      "273  112.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "274  134.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "275  170.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "276  146.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "277  138.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     2.0   -9.0   \n",
      "278  154.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "279  130.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "280  110.0  ...     1.0     2.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "281  130.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "282  128.0  ...    -9.0    -9.0     9.0   -9.0   -9.0      0.0    -9.0   -9.0   \n",
      "283    0.0  ...     3.0     0.0   104.0    1.0  234.0      1.0   234.0    0.0   \n",
      "284  -92.0  ...    16.0  2002.0  1502.0    0.0    9.0    118.0     0.0    0.0   \n",
      "285    1.0  ...    -9.0  1183.0     0.0    0.0    0.0      0.0     0.0   83.0   \n",
      "286   80.0  ...    -9.0    -9.0    -9.0 -950.0   90.0      6.0    25.0  110.0   \n",
      "287    1.0  ...     0.0    -9.0    -9.0   -9.0    4.0      0.0    -9.0   -9.0   \n",
      "288   10.0  ...    80.0     0.0     3.0    0.0    3.0      0.0    60.0   60.0   \n",
      "289   -9.0  ...     1.0     7.0     1.0    0.0    5.0  26705.0    64.0    1.0   \n",
      "290    2.0  ...     7.0    17.0     0.0   23.0    0.0     23.0     0.0   15.0   \n",
      "291    0.0  ...     1.0    -9.0     1.0    1.0    1.0      0.0     1.0   -9.0   \n",
      "292   -9.0  ...     4.0     1.0     0.0    1.0  111.0    182.0  1355.0    0.0   \n",
      "293    1.0  ...     9.0     3.0    -9.0  -99.0    3.0     -9.0   -99.0    1.0   \n",
      "294  125.0  ...    81.0     0.0     1.0    1.0    1.0      0.0    81.0    4.0   \n",
      "295   -9.0  ...     1.0     1.0     1.0    1.0    1.0      1.0     1.0   -9.0   \n",
      "296    1.0  ...    26.0   -26.0     0.0    0.0   -9.0     -6.0     0.0   -9.0   \n",
      "\n",
      "         74     75  \n",
      "0      -9.0    0.0  \n",
      "1      -9.0    0.0  \n",
      "2      -9.0    0.0  \n",
      "3      -9.0    0.0  \n",
      "4      -9.0    0.0  \n",
      "5      -9.0    0.0  \n",
      "6      -9.0    0.0  \n",
      "7      -9.0    0.0  \n",
      "8      -9.0    0.0  \n",
      "9      -9.0    0.0  \n",
      "10     -9.0    0.0  \n",
      "11     -9.0    0.0  \n",
      "12     -9.0    0.0  \n",
      "13     -9.0    0.0  \n",
      "14     -9.0    0.0  \n",
      "15     -9.0    0.0  \n",
      "16     -9.0    0.0  \n",
      "17     -9.0    0.0  \n",
      "18     -9.0    0.0  \n",
      "19     -9.0    0.0  \n",
      "20     -9.0    0.0  \n",
      "21     -9.0    0.0  \n",
      "22     -9.0    0.0  \n",
      "23     -9.0    0.0  \n",
      "24     -9.0    0.0  \n",
      "25     -9.0    0.0  \n",
      "26     -9.0    0.0  \n",
      "27     -9.0    0.0  \n",
      "28     -9.0    0.0  \n",
      "29     -9.0    0.0  \n",
      "..      ...    ...  \n",
      "267    -9.0    0.0  \n",
      "268    -9.0    0.0  \n",
      "269    -9.0    0.0  \n",
      "270    -9.0    0.0  \n",
      "271    -9.0    0.0  \n",
      "272    -9.0    0.0  \n",
      "273    -9.0    0.0  \n",
      "274    -9.0    0.0  \n",
      "275    -9.0    0.0  \n",
      "276    -9.0    0.0  \n",
      "277    -9.0    0.0  \n",
      "278    -9.0    0.0  \n",
      "279    -9.0    0.0  \n",
      "280    -9.0    0.0  \n",
      "281    -9.0    0.0  \n",
      "282    -9.0   -9.0  \n",
      "283     0.0    1.0  \n",
      "284     0.0    0.0  \n",
      "285     0.0    0.0  \n",
      "286     0.0  110.0  \n",
      "287    -9.0    4.0  \n",
      "288     0.0    0.0  \n",
      "289    -9.0    6.0  \n",
      "290     1.0    1.0  \n",
      "291    -9.0   26.0  \n",
      "292   465.0    0.0  \n",
      "293    -9.0   -9.0  \n",
      "294  1084.0    0.0  \n",
      "295     1.0    1.0  \n",
      "296     0.0    0.0  \n",
      "\n",
      "[297 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data= pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/cleveland.data',index_col=False)\n",
    "#print data\n",
    "df = pd.DataFrame(np.random.randn(297, 76))\n",
    "#print df\n",
    "a= ''\n",
    "for index, row in data.iterrows():\n",
    "    a+= str(row[0])+' '\n",
    "#print a\n",
    "\n",
    "import urllib\n",
    "\n",
    "link = \"http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/cleveland.data\"\n",
    "f = urllib.urlopen(link)\n",
    "myfile = f.read()\n",
    "my_list = myfile.split()\n",
    "print len(my_list)\n",
    "count = 0\n",
    "for i, row in df.iterrows():\n",
    "    for j in range (0,76):\n",
    "        try:\n",
    "            a = float(my_list[count])\n",
    "            df.at[i,j] = a\n",
    "        except ValueError:\n",
    "            df.at[i,j] = 0\n",
    "        count = count + 1\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n",
      "KNN:\n",
      "Test set accuracy: 0.55\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy on training set: 0.991\n",
      "Accuracy on test set: 0.704\n",
      "\n",
      "Random Forest:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.873\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy on training set: 0.848\n",
      "Accuracy on test set: 0.803\n",
      "\n",
      "SVM:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.549\n",
      "\n",
      "Decision Tree Regressor:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.924\n",
      "\n",
      "Random Forest Regressor:\n",
      "Accuracy on training set: 0.980\n",
      "Accuracy on test set: 0.920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "my_list2 = myfile.split(\"name\")\n",
    "df2 = pd.DataFrame(np.random.randn(282, 75))\n",
    "print len(my_list2)\n",
    "lst = my_list2\n",
    "lst = lst[:len(lst)-12]\n",
    "for i, row in df2.iterrows():\n",
    "    row = lst[i].split()\n",
    "    for j in range (0,75):\n",
    "        try:\n",
    "            a = float(row[j])\n",
    "            df2.at[i,j] = a\n",
    "        except ValueError:\n",
    "            df2.at[i,j] = -999\n",
    "#print df2\n",
    "\n",
    "X = df2.loc[:, df2.columns != 57]\n",
    "y = df2[57]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=0)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=10, weights='uniform')  \n",
    "classifier.fit(X_train, y_train)\n",
    "print (\"KNN:\")\n",
    "print(\"Test set accuracy: {:.2f}\\n\".format(classifier.score(X_test, y_test)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10, max_features=10, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print (\"Decision Tree:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=80, max_features=16, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "print (\"Random Forest:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(forest.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "NB_clf.fit(X_train, y_train)\n",
    "print (\"Naive Bayes:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(NB_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(NB_clf.score(X_test, y_test)))\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1)\n",
    "svm.fit(X_train, y_train)\n",
    "print (\"SVM:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(svm.score(X_test, y_test)))\n",
    "\n",
    "reg = DecisionTreeRegressor(min_samples_split=3)\n",
    "reg.fit(X_train, y_train)\n",
    "print (\"Decision Tree Regressor:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(reg.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(reg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print (\"Random Forest Regressor:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "select = SelectPercentile(percentile=10)\n",
    "\n",
    "select.fit(X, y)\n",
    "# transform training set\n",
    "X_train_univariant = select.transform(X)\n",
    "print len(X_train_univariant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Test set accuracy: 0.63\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.986\n",
      "\n",
      "Random Forest:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.972\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy on training set: 0.886\n",
      "Accuracy on test set: 0.845\n",
      "\n",
      "SVM:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.915\n",
      "\n",
      "Decision Tree Regressor:\n",
      "Accuracy on training set: 0.998\n",
      "Accuracy on test set: 0.998\n",
      "\n",
      "Random Forest Regressor:\n",
      "Accuracy on training set: 0.991\n",
      "Accuracy on test set: 0.984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_univariant, y, stratify=y, random_state=0)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=10, weights='uniform')  \n",
    "classifier.fit(X_train, y_train)\n",
    "print (\"KNN:\")\n",
    "print(\"Test set accuracy: {:.2f}\\n\".format(classifier.score(X_test, y_test)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print (\"Decision Tree:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=80, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "print (\"Random Forest:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(forest.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "NB_clf.fit(X_train, y_train)\n",
    "print (\"Naive Bayes:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(NB_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(NB_clf.score(X_test, y_test)))\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1)\n",
    "svm.fit(X_train, y_train)\n",
    "print (\"SVM:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(svm.score(X_test, y_test)))\n",
    "\n",
    "reg = DecisionTreeRegressor(min_samples_split=3)\n",
    "reg.fit(X_train, y_train)\n",
    "print (\"Decision Tree Regressor:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(reg.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(reg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print (\"Random Forest Regressor:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "select = SelectFromModel(\n",
    "    RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    threshold=\"median\")\n",
    "\n",
    "select.fit(X, y)\n",
    "X_train_model_based = select.transform(X)\n",
    "print len(X_train_model_based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Test set accuracy: 0.55\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.901\n",
      "\n",
      "Random Forest:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.803\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy on training set: 0.915\n",
      "Accuracy on test set: 0.803\n",
      "\n",
      "SVM:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.549\n",
      "\n",
      "Decision Tree Regressor:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.886\n",
      "\n",
      "Random Forest Regressor:\n",
      "Accuracy on training set: 0.980\n",
      "Accuracy on test set: 0.911\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_model_based, y, stratify=y, random_state=0)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=10, weights='uniform')  \n",
    "classifier.fit(X_train, y_train)\n",
    "print (\"KNN:\")\n",
    "print(\"Test set accuracy: {:.2f}\\n\".format(classifier.score(X_test, y_test)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print (\"Decision Tree:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=80, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "print (\"Random Forest:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(forest.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "NB_clf.fit(X_train, y_train)\n",
    "print (\"Naive Bayes:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(NB_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(NB_clf.score(X_test, y_test)))\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1)\n",
    "svm.fit(X_train, y_train)\n",
    "print (\"SVM:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(svm.score(X_test, y_test)))\n",
    "\n",
    "reg = DecisionTreeRegressor(min_samples_split=3)\n",
    "reg.fit(X_train, y_train)\n",
    "print (\"Decision Tree Regressor:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(reg.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(reg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print (\"Random Forest Regressor:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "             n_features_to_select=16)\n",
    "\n",
    "select.fit(X, y)\n",
    "X_train_iterative = select.transform(X)\n",
    "print len(X_train_iterative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Test set accuracy: 0.56\n",
      "\n",
      "Decision Tree:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.930\n",
      "\n",
      "Random Forest:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.930\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy on training set: 0.910\n",
      "Accuracy on test set: 0.873\n",
      "\n",
      "SVM:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.549\n",
      "\n",
      "Decision Tree Regressor:\n",
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.962\n",
      "\n",
      "Random Forest Regressor:\n",
      "Accuracy on training set: 0.985\n",
      "Accuracy on test set: 0.949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_iterative, y, stratify=y, random_state=0)\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=10, weights='uniform')  \n",
    "classifier.fit(X_train, y_train)\n",
    "print (\"KNN:\")\n",
    "print(\"Test set accuracy: {:.2f}\\n\".format(classifier.score(X_test, y_test)))\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print (\"Decision Tree:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(tree.score(X_test, y_test)))\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=80, random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "print (\"Random Forest:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(forest.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "NB_clf = GaussianNB()\n",
    "NB_clf.fit(X_train, y_train)\n",
    "print (\"Naive Bayes:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(NB_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(NB_clf.score(X_test, y_test)))\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1, gamma=1)\n",
    "svm.fit(X_train, y_train)\n",
    "print (\"SVM:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(svm.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(svm.score(X_test, y_test)))\n",
    "\n",
    "reg = DecisionTreeRegressor(min_samples_split=3)\n",
    "reg.fit(X_train, y_train)\n",
    "print (\"Decision Tree Regressor:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(reg.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(reg.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print (\"Random Forest Regressor:\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\\n\".format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
